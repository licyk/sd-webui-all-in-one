{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlyptNJ2ICnN"
      },
      "source": [
        "# Fooooooooooooooocus\n",
        "#### Colab NoteBook Created by [licyk](https://github.com/licyk)\n",
        "\n",
        "Jupyter Notebook ä»“åº“ï¼š[licyk/sd-webui-all-in-one](https://github.com/licyk/sd-webui-all-in-one)\n",
        "\n",
        "è¿™æ˜¯é€‚ç”¨äº [Colab](https://colab.research.google.com) éƒ¨ç½² Fooocus çš„ Jupyter Notebookï¼Œä½¿ç”¨æ—¶è¯·æŒ‰é¡ºåºæ‰§è¡Œ Jupyter Notebook å•å…ƒã€‚\n",
        "\n",
        "## åŠŸèƒ½\n",
        "1. ç¯å¢ƒé…ç½®ï¼šé…ç½®å®‰è£…çš„ PyTorch ç‰ˆæœ¬ã€å†…ç½‘ç©¿é€çš„æ–¹å¼ã€‚\n",
        "2. å®‰è£… Fooocusï¼šæ ¹æ®ç¯å¢ƒé…ç½®å®‰è£… Fooocus å’Œè¿è¡Œç¯å¢ƒã€‚\n",
        "3. ä¸‹è½½æ¨¡å‹ï¼šä¸‹è½½å¯é€‰åˆ—è¡¨ä¸­çš„æ¨¡å‹ã€‚\n",
        "4. å¯åŠ¨ Fooocusï¼šå¯åŠ¨ Fooocusï¼Œå¹¶æ˜¾ç¤ºè®¿é—®åœ°å€ã€‚\n",
        "\n",
        "## æç¤º\n",
        "1. [Ngrok](https://ngrok.com) å†…ç½‘ç©¿é€åœ¨ä½¿ç”¨å‰éœ€è¦å¡«å†™ Ngrok Tokenï¼Œå¯åœ¨ [Ngrok](https://ngrok.com) å®˜ç½‘è·å–ã€‚\n",
        "2. å…¶ä»–åŠŸèƒ½æœ‰è‡ªå®šä¹‰æ¨¡å‹ä¸‹è½½ç­‰åŠŸèƒ½ï¼Œæ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä½¿ç”¨ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ‘‡ ç¯å¢ƒé…ç½®\n",
        "INIT_CONFIG = 1\n",
        "# æ¶ˆæ¯æ ¼å¼è¾“å‡º\n",
        "def echo(msg):\n",
        "    print(f\":: {msg}\")\n",
        "\n",
        "\n",
        "\n",
        "# ARIA2\n",
        "class ARIA2:\n",
        "    WORKSPACE = \"\"\n",
        "    WORKFOLDER = \"\"\n",
        "\n",
        "\n",
        "    def __init__(self, workspace, workfolder) -> None:\n",
        "        self.WORKSPACE = workspace\n",
        "        self.WORKFOLDER = workfolder\n",
        "\n",
        "\n",
        "    # ä¸‹è½½å™¨\n",
        "    def aria2(self, url, path, filename):\n",
        "        import os\n",
        "        if not os.path.exists(path + \"/\" + filename):\n",
        "            echo(f\"å¼€å§‹ä¸‹è½½ {filename} ï¼Œè·¯å¾„: {path}/{filename}\")\n",
        "            !aria2c --console-log-level=error -c -x 16 -s 16 \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
        "            if os.path.exists(path + \"/\" + filename) and not os.path.exists(path + \"/\" + filename + \".aria2\"):\n",
        "                echo(f\"{filename} ä¸‹è½½å®Œæˆ\")\n",
        "            else:\n",
        "                echo(f\"{filename} ä¸‹è½½ä¸­æ–­\")\n",
        "        else:\n",
        "            if os.path.exists(path + \"/\" + filename + \".aria2\"):\n",
        "                echo(f\"å¼€å§‹ä¸‹è½½ {filename} ï¼Œè·¯å¾„: {path}/{filename}\")\n",
        "                !aria2c --console-log-level=error -c -x 16 -s 16 \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
        "                if os.path.exists(path + \"/\" + filename) and not os.path.exists(path + \"/\" + filename + \".aria2\"):\n",
        "                    echo(f\"{filename} ä¸‹è½½å®Œæˆ\")\n",
        "                else:\n",
        "                    echo(f\"{filename} ä¸‹è½½ä¸­æ–­\")\n",
        "            else:\n",
        "                echo(f\"{filename} æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·¯å¾„: {path}/{filename}\")\n",
        "\n",
        "\n",
        "    # å¤§æ¨¡å‹ä¸‹è½½\n",
        "    def get_sd_model(self, url, filename):\n",
        "        pass\n",
        "\n",
        "\n",
        "    # loraä¸‹è½½\n",
        "    def get_lora_model(self, url, filename):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "# GIT\n",
        "class GIT:\n",
        "    WORKSPACE = \"\"\n",
        "    WORKFOLDER = \"\"\n",
        "\n",
        "\n",
        "    def __init__(self, workspace, workfolder) -> None:\n",
        "        self.WORKSPACE = workspace\n",
        "        self.WORKFOLDER = workfolder\n",
        "\n",
        "\n",
        "    # æ£€æµ‹è¦å…‹éš†çš„é¡¹ç›®æ˜¯å¦å­˜åœ¨äºæŒ‡å®šè·¯å¾„\n",
        "    def exists(self, addr=None, path=None, name=None):\n",
        "        import os\n",
        "        if addr is not None:\n",
        "            if path is None and name is None:\n",
        "                path = os.getcwd() + \"/\" + addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
        "            elif path is None and name is not None:\n",
        "                path = os.getcwd() + \"/\" + name\n",
        "            elif path is not None and name is None:\n",
        "                path = os.path.normpath(path) + \"/\" + addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
        "\n",
        "        if os.path.exists(path):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    # å…‹éš†é¡¹ç›®\n",
        "    def clone(self, addr, path=None, name=None):\n",
        "        import os\n",
        "        repo = addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
        "        if not self.exists(addr, path, name):\n",
        "            echo(f\"å¼€å§‹ä¸‹è½½ {repo}\")\n",
        "            if path is None and name is None:\n",
        "                path = os.getcwd()\n",
        "                name = repo\n",
        "            elif path is not None and name is None:\n",
        "                name = repo\n",
        "            elif path is None and name is not None:\n",
        "                path = os.getcwd()\n",
        "            !git clone {addr} \"{path}/{name}\" --recurse-submodules\n",
        "        else:\n",
        "            echo(f\"{repo} å·²å­˜åœ¨\")\n",
        "\n",
        "\n",
        "\n",
        "# TUNNEL\n",
        "class TUNNEL:\n",
        "    LOCALHOST_RUN = \"localhost.run\"\n",
        "    REMOTE_MOE = \"remote.moe\"\n",
        "    WORKSPACE = \"\"\n",
        "    WORKFOLDER = \"\"\n",
        "    PORT = \"\"\n",
        "\n",
        "\n",
        "    def __init__(self, workspace, workfolder, port) -> None:\n",
        "        self.WORKSPACE = workspace\n",
        "        self.WORKFOLDER = workfolder\n",
        "        self.PORT = port\n",
        "\n",
        "\n",
        "    # ngrokå†…ç½‘ç©¿é€\n",
        "    def ngrok(self, ngrok_token: str):\n",
        "        from pyngrok import conf, ngrok\n",
        "        conf.get_default().auth_token = ngrok_token\n",
        "        conf.get_default().monitor_thread = False\n",
        "        port = self.PORT\n",
        "        ssh_tunnels = ngrok.get_tunnels(conf.get_default())\n",
        "        if len(ssh_tunnels) == 0:\n",
        "            ssh_tunnel = ngrok.connect(port, bind_tls=True)\n",
        "            return ssh_tunnel.public_url\n",
        "        else:\n",
        "            return ssh_tunnels[0].public_url\n",
        "\n",
        "\n",
        "    # cloudflareå†…ç½‘ç©¿é€\n",
        "    def cloudflare(self):\n",
        "        from pycloudflared import try_cloudflare\n",
        "        port = self.PORT\n",
        "        urls = try_cloudflare(port).tunnel\n",
        "        return urls\n",
        "\n",
        "\n",
        "    from typing import Union\n",
        "    from pathlib import Path\n",
        "\n",
        "    # ç”Ÿæˆsshå¯†é’¥\n",
        "    def gen_key(self, path: Union[str, Path]) -> None:\n",
        "        import subprocess\n",
        "        import shlex\n",
        "        from pathlib import Path\n",
        "        path = Path(path)\n",
        "        arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "        args = shlex.split(arg_string)\n",
        "        subprocess.run(args, check=True)\n",
        "        path.chmod(0o600)\n",
        "\n",
        "\n",
        "    # sshå†…ç½‘ç©¿é€\n",
        "    def ssh_tunnel(self, host: str) -> None:\n",
        "        import subprocess\n",
        "        import atexit\n",
        "        import shlex\n",
        "        import re\n",
        "        import os\n",
        "        from pathlib import Path\n",
        "        from tempfile import TemporaryDirectory\n",
        "\n",
        "        ssh_name = \"id_rsa\"\n",
        "        ssh_path = Path(self.WORKSPACE) / ssh_name\n",
        "        port = self.PORT\n",
        "\n",
        "        tmp = None\n",
        "        if not ssh_path.exists():\n",
        "            try:\n",
        "                self.gen_key(ssh_path)\n",
        "            # write permission error or etc\n",
        "            except subprocess.CalledProcessError:\n",
        "                tmp = TemporaryDirectory()\n",
        "                ssh_path = Path(tmp.name) / ssh_name\n",
        "                self.gen_key(ssh_path)\n",
        "\n",
        "        arg_string = f\"ssh -R 80:127.0.0.1:{port} -o StrictHostKeyChecking=no -i {ssh_path.as_posix()} {host}\"\n",
        "        args = shlex.split(arg_string)\n",
        "\n",
        "        tunnel = subprocess.Popen(\n",
        "            args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, encoding=\"utf-8\"\n",
        "        )\n",
        "\n",
        "        atexit.register(tunnel.terminate)\n",
        "        if tmp is not None:\n",
        "            atexit.register(tmp.cleanup)\n",
        "\n",
        "        tunnel_url = \"\"\n",
        "        LOCALHOST_RUN = self.LOCALHOST_RUN\n",
        "        lines = 27 if host == LOCALHOST_RUN else 5\n",
        "        localhostrun_pattern = re.compile(r\"(?P<url>https?://\\S+\\.lhr\\.life)\")\n",
        "        remotemoe_pattern = re.compile(r\"(?P<url>https?://\\S+\\.remote\\.moe)\")\n",
        "        pattern = localhostrun_pattern if host == LOCALHOST_RUN else remotemoe_pattern\n",
        "\n",
        "        for _ in range(lines):\n",
        "            line = tunnel.stdout.readline()\n",
        "            if line.startswith(\"Warning\"):\n",
        "                print(line, end=\"\")\n",
        "\n",
        "            url_match = pattern.search(line)\n",
        "            if url_match:\n",
        "                tunnel_url = url_match.group(\"url\")\n",
        "                if lines == 27:\n",
        "                    os.environ['LOCALHOST_RUN'] = tunnel_url\n",
        "                    return tunnel_url\n",
        "                else:\n",
        "                    os.environ['REMOTE_MOE'] = tunnel_url\n",
        "                    return tunnel_url\n",
        "                # break\n",
        "        else:\n",
        "            echo(f\"å¯åŠ¨ {host} å†…ç½‘ç©¿é€å¤±è´¥\")\n",
        "\n",
        "\n",
        "    # localhost.runç©¿é€\n",
        "    def localhost_run(self):\n",
        "        urls = self.ssh_tunnel(self.LOCALHOST_RUN)\n",
        "        return urls\n",
        "\n",
        "\n",
        "    # remote.moeå†…ç½‘ç©¿é€\n",
        "    def remote_moe(self):\n",
        "        urls = self.ssh_tunnel(self.REMOTE_MOE)\n",
        "        return urls\n",
        "\n",
        "\n",
        "    # gradioå†…ç½‘ç©¿é€\n",
        "    def gradio(self):\n",
        "        import subprocess\n",
        "        import shlex\n",
        "        import atexit\n",
        "        import re\n",
        "        port = self.PORT\n",
        "        cmd = f\"gradio-tunneling --port {port}\"\n",
        "        cmd = shlex.split(cmd)\n",
        "        tunnel = subprocess.Popen(\n",
        "            cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, encoding=\"utf-8\"\n",
        "        )\n",
        "\n",
        "        atexit.register(tunnel.terminate)\n",
        "\n",
        "        tunnel_url = \"\"\n",
        "        lines = 5\n",
        "        gradio_pattern = re.compile(r\"(?P<url>https?://\\S+\\.gradio\\.live)\")\n",
        "        pattern = gradio_pattern\n",
        "\n",
        "        for _ in range(lines):\n",
        "            line = tunnel.stdout.readline()\n",
        "            if line.startswith(\"Warning\"):\n",
        "                print(line, end=\"\")\n",
        "            url_match = pattern.search(line)\n",
        "            if url_match:\n",
        "                tunnel_url = url_match.group(\"url\")\n",
        "                return tunnel_url\n",
        "        else:\n",
        "            echo(f\"å¯åŠ¨ Gradio å†…ç½‘ç©¿é€å¤±è´¥\")\n",
        "\n",
        "\n",
        "    # å¯åŠ¨å†…ç½‘ç©¿é€\n",
        "    def start(self, ngrok=False, ngrok_token=None, cloudflare=False, remote_moe=False, localhost_run=False, gradio=False):\n",
        "        if cloudflare is True or ngrok is True or ngrok_token is not None or remote_moe is True or localhost_run is True or gradio is True:\n",
        "            echo(\"å¯åŠ¨å†…ç½‘ç©¿é€\")\n",
        "\n",
        "        if cloudflare is True:\n",
        "            cloudflare_url = self.cloudflare()\n",
        "        else:\n",
        "            cloudflare_url = None\n",
        "\n",
        "        if ngrok is True and ngrok_token is not None:\n",
        "            ngrok_url = self.ngrok(ngrok_token)\n",
        "        else:\n",
        "            ngrok_url = None\n",
        "\n",
        "        if remote_moe is True:\n",
        "            remote_moe_url = self.remote_moe()\n",
        "        else:\n",
        "            remote_moe_url = None\n",
        "\n",
        "        if localhost_run is True:\n",
        "            localhost_run_url = self.localhost_run()\n",
        "        else:\n",
        "            localhost_run_url = None\n",
        "\n",
        "        if gradio is True:\n",
        "            gradio_url = self.gradio()\n",
        "        else:\n",
        "            gradio_url = None\n",
        "\n",
        "        echo(\"ä¸‹æ–¹ä¸ºè®¿é—®åœ°å€\")\n",
        "        print(\"==================================================================================\")\n",
        "        echo(f\"CloudFlare: {cloudflare_url}\")\n",
        "        echo(f\"Ngrok: {ngrok_url}\")\n",
        "        echo(f\"remote.moe: {remote_moe_url}\")\n",
        "        echo(f\"localhost_run: {localhost_run_url}\")\n",
        "        echo(f\"Gradio: {gradio_url}\")\n",
        "        print(\"==================================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ENV\n",
        "class ENV:\n",
        "    WORKSPACE = \"\"\n",
        "    WORKFOLDER = \"\"\n",
        "\n",
        "\n",
        "    def __init__(self, workspace, workfolder) -> None:\n",
        "        self.WORKSPACE = workspace\n",
        "        self.WORKFOLDER = workfolder\n",
        "\n",
        "\n",
        "    # å‡†å¤‡ipynbç¬”è®°è‡ªèº«åŠŸèƒ½çš„ä¾èµ–\n",
        "    def prepare_env_depend(self, use_uv=False):\n",
        "        pip_mirror = \"--index-url https://pypi.python.org/simple --find-links https://download.pytorch.org/whl/cu121/torch_stable.html\"\n",
        "        echo(\"å®‰è£…è‡ªèº«ç»„ä»¶ä¾èµ–\")\n",
        "        if use_uv:\n",
        "            !pip install uv {pip_mirror}\n",
        "            !uv pip install pyngrok pycloudflared gradio-tunneling {pip_mirror} --system --quiet\n",
        "        else:\n",
        "            !pip install pyngrok pycloudflared gradio-tunneling {pip_mirror}\n",
        "\n",
        "        !apt update\n",
        "        !apt install aria2 ssh google-perftools -y\n",
        "\n",
        "\n",
        "    # å®‰è£…pytorchå’Œxformers\n",
        "    def prepare_torch(self, torch_ver, xformers_ver, use_uv=False):\n",
        "        pip_mirror = \"--index-url https://pypi.python.org/simple --find-links https://download.pytorch.org/whl/cu121/torch_stable.html\"\n",
        "        if use_uv:\n",
        "            if torch_ver != \"\":\n",
        "                echo(\"å®‰è£… PyTorch\")\n",
        "                !uv pip install {torch_ver} {pip_mirror} --system --quiet\n",
        "            if xformers_ver != \"\":\n",
        "                echo(\"å®‰è£… xFormers\")\n",
        "                !uv pip install {xformers_ver} {pip_mirror} --no-deps --system --quiet\n",
        "        else:\n",
        "            if torch_ver != \"\":\n",
        "                echo(\"å®‰è£… PyTorch\")\n",
        "                !pip install {torch_ver} {pip_mirror}\n",
        "            if xformers_ver != \"\":\n",
        "                echo(\"å®‰è£… xFormers\")\n",
        "                !pip install {xformers_ver} {pip_mirror} --no-deps\n",
        "\n",
        "\n",
        "\n",
        "    # å®‰è£…requirements.txtä¾èµ–\n",
        "    def install_requirements(self, path, use_uv=False):\n",
        "        import os\n",
        "        pip_mirror = \"--index-url https://pypi.python.org/simple --find-links https://download.pytorch.org/whl/cu121/torch_stable.html\"\n",
        "        if os.path.exists(path):\n",
        "            echo(\"å®‰è£…ä¾èµ–\")\n",
        "            if use_uv:\n",
        "                !uv pip install -r \"{path}\" {pip_mirror} --system --quiet\n",
        "            else:\n",
        "                !pip install -r \"{path}\" {pip_mirror}\n",
        "        else:\n",
        "            echo(\"ä¾èµ–æ–‡ä»¶è·¯å¾„ä¸ºç©º\")\n",
        "\n",
        "\n",
        "\n",
        "    # é€‚ç”¨äºcolabçš„å†…å­˜ä¼˜åŒ–\n",
        "    def tcmalloc_colab(self):\n",
        "        echo(\"é…ç½®å†…å­˜ä¼˜åŒ–\")\n",
        "        import os\n",
        "        aria2 = ARIA2(self.WORKSPACE, self.WORKFOLDER)\n",
        "        path = self.WORKSPACE\n",
        "        libtcmalloc_path = self.WORKSPACE + \"/libtcmalloc_minimal.so.4\"\n",
        "        aria2.aria2(\"https://github.com/licyk/term-sd/releases/download/archive/libtcmalloc_minimal.so.4\", path, \"libtcmalloc_minimal.so.4\")\n",
        "        os.environ[\"LD_PRELOAD\"] = libtcmalloc_path\n",
        "\n",
        "\n",
        "\n",
        "# MANAGER\n",
        "class MANAGER:\n",
        "    WORKSPACE = \"\"\n",
        "    WORKFOLDER = \"\"\n",
        "\n",
        "\n",
        "    def __init__(self, workspace, workfolder) -> None:\n",
        "        self.WORKSPACE = workspace\n",
        "        self.WORKFOLDER = workfolder\n",
        "\n",
        "\n",
        "    # æ¸…ç†ipynbç¬”è®°çš„è¾“å‡º\n",
        "    def clear_up(self, opt):\n",
        "        from IPython.display import clear_output\n",
        "        clear_output(wait=opt)\n",
        "\n",
        "\n",
        "    # æ£€æŸ¥gpuæ˜¯å¦å¯ç”¨\n",
        "    def check_gpu(self):\n",
        "        echo(\"æ£€æµ‹ GPU æ˜¯å¦å¯ç”¨\")\n",
        "        import tensorflow as tf\n",
        "        echo(f\"TensorFlow ç‰ˆæœ¬: {tf.__version__}\")\n",
        "        if tf.test.gpu_device_name():\n",
        "            echo(\"GPU å¯ç”¨\")\n",
        "        else:\n",
        "            echo(\"GPU ä¸å¯ç”¨\")\n",
        "            raise Exception(\"\\næ²¡æœ‰ä½¿ç”¨GPUï¼Œè¯·åœ¨ä»£ç æ‰§è¡Œç¨‹åº-æ›´æ”¹è¿è¡Œæ—¶ç±»å‹-è®¾ç½®ä¸ºGPUï¼\\nå¦‚æœä¸èƒ½ä½¿ç”¨GPUï¼Œå»ºè®®æ›´æ¢è´¦å·ï¼\")\n",
        "\n",
        "\n",
        "    # é…ç½®google drive\n",
        "    def config_google_drive(self):\n",
        "        echo(\"æŒ‚è½½ Google Drive\")\n",
        "        import os\n",
        "        if not os.path.exists('/content/drive/MyDrive'):\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            echo(\"Google Dirve æŒ‚è½½å®Œæˆ\")\n",
        "        else:\n",
        "            echo(\"Google Drive å·²æŒ‚è½½\")\n",
        "\n",
        "        # æ£€æµ‹å¹¶åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹\n",
        "        if os.path.exists('/content/drive/MyDrive'):\n",
        "            if not os.path.exists('/content/drive/MyDrive/fooocus_output'):\n",
        "                echo(\"åœ¨ Google Drive åˆ›å»º fooocus_ouput æ–‡ä»¶å¤¹\")\n",
        "                !mkdir -p /content/drive/MyDrive/fooocus_output\n",
        "        else:\n",
        "            raise Exception(\"æœªæŒ‚è½½ Google Driveï¼Œè¯·é‡æ–°æŒ‚è½½åé‡è¯•ï¼\")\n",
        "\n",
        "\n",
        "\n",
        "# FOOOCUS\n",
        "class FOOOCUS(ARIA2, GIT, TUNNEL, MANAGER, ENV):\n",
        "    WORKSPACE = \"\"\n",
        "    WORKFOLDER = \"\"\n",
        "\n",
        "    tun = TUNNEL(WORKSPACE, WORKFOLDER, 7865)\n",
        "\n",
        "    def __init__(self, workspace, workfolder) -> None:\n",
        "        self.WORKSPACE = workspace\n",
        "        self.WORKFOLDER = workfolder\n",
        "\n",
        "\n",
        "    # ä¸‹è½½å¤§æ¨¡å‹\n",
        "    def get_sd_model(self, url, filename = None):\n",
        "        path = self.WORKSPACE + \"/\" + self.WORKFOLDER + \"/models/checkpoints\"\n",
        "        filename = url.split(\"/\").pop() if filename is None else filename\n",
        "        super().aria2(url, path, filename)\n",
        "\n",
        "\n",
        "    # ä¸‹è½½loraæ¨¡å‹\n",
        "    def get_lora_model(self, url, filename = None):\n",
        "        path = self.WORKSPACE + \"/\" + self.WORKFOLDER + \"/models/loras\"\n",
        "        filename = url.split(\"/\").pop() if filename is None else filename\n",
        "        super().aria2(url, path, filename)\n",
        "\n",
        "\n",
        "    # ä¸‹è½½é…ç½®æ–‡ä»¶\n",
        "    def install_config(self):\n",
        "        path = self.WORKSPACE + \"/\" + self.WORKFOLDER\n",
        "        echo(\"ä¸‹è½½é…ç½®æ–‡ä»¶\")\n",
        "        self.aria2(\"https://github.com/licyk/term-sd/releases/download/archive/fooocus_config.json\", path + \"/presets\", \"custom.json\")\n",
        "        self.aria2(\"https://github.com/licyk/term-sd/releases/download/archive/fooocus_path_config_colab.json\", path, \"config.txt\")\n",
        "        self.aria2(\"https://github.com/licyk/term-sd/releases/download/archive/fooocus_zh_cn.json\", path + \"/language\", \"zh.json\")\n",
        "\n",
        "\n",
        "    # é¢„ä¸‹è½½æ¨¡å‹\n",
        "    def pre_download_model(self, path):\n",
        "        import os\n",
        "        import json\n",
        "\n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                with open(path, \"r\", encoding=\"utf8\") as file:\n",
        "                    data = json.load(file)\n",
        "                    echo(\"é¢„ä¸‹è½½ Fooocus æ¨¡å‹ä¸­\")\n",
        "            except Exception:\n",
        "                # json æ–‡ä»¶æ ¼å¼å‡ºç°é—®é¢˜\n",
        "                data = {}\n",
        "        else:\n",
        "            data = {}\n",
        "\n",
        "        sd_model_list = data.get(\"checkpoint_downloads\") if not isinstance(data.get(\"checkpoint_downloads\"), type(None)) else {}\n",
        "        lora_list = data.get(\"lora_downloads\") if not isinstance(data.get(\"lora_downloads\"), type(None)) else {}\n",
        "        vae_list = data.get(\"vae_downloads\") if not isinstance(data.get(\"vae_downloads\"), type(None)) else {}\n",
        "        sd_model_path = os.path.join(self.WORKSPACE, self.WORKFOLDER, \"models\", \"checkpoints\")\n",
        "        lora_path = os.path.join(self.WORKSPACE, self.WORKFOLDER, \"models\", \"loras\")\n",
        "        vae_path = os.path.join(self.WORKSPACE, self.WORKFOLDER, \"models\", \"vae\")\n",
        "\n",
        "        for i in sd_model_list:\n",
        "            super().aria2(sd_model_list.get(i), sd_model_path, i)\n",
        "\n",
        "        for i in lora_list:\n",
        "            super().aria2(lora_list.get(i), lora_path, i)\n",
        "\n",
        "        for i in vae_list:\n",
        "            super().aria2(vae_list.get(i), vae_path, i)\n",
        "\n",
        "        echo(\"é¢„ä¸‹è½½ Fooocus æ¨¡å‹å®Œæˆ\")\n",
        "\n",
        "\n",
        "    # å®‰è£…fooocus\n",
        "    # å·²çŸ¥ä½¿ç”¨ uv åŒ…ç®¡ç†å™¨çš„ç¼ºé™·: https://github.com/astral-sh/uv/blob/main/PIP_COMPATIBILITY.md#local-version-identifiers\n",
        "    def install(self, torch_ver, xformers_ver, use_uv):\n",
        "        import os\n",
        "        req_file = os.path.join(self.WORKSPACE, self.WORKFOLDER, \"requirements_versions.txt\")\n",
        "        config_file = os.path.join(self.WORKSPACE, self.WORKFOLDER, \"presets\", \"custom.json\")\n",
        "        self.check_gpu()\n",
        "        self.prepare_env_depend(use_uv)\n",
        "        self.clone(\"https://github.com/lllyasviel/Fooocus\", self.WORKSPACE)\n",
        "        os.chdir(os.path.join(self.WORKSPACE, self.WORKFOLDER))\n",
        "        self.prepare_torch(torch_ver, xformers_ver, use_uv)\n",
        "        self.install_requirements(req_file, use_uv)\n",
        "        if use_uv: # çº æ­£pytorchç‰ˆæœ¬\n",
        "            self.prepare_torch(torch_ver, xformers_ver, use_uv)\n",
        "\n",
        "        self.install_config()\n",
        "        self.tcmalloc_colab()\n",
        "        self.pre_download_model(config_file)\n",
        "\n",
        "\n",
        "#######################################################\n",
        "\n",
        "\n",
        "#@markdown ### æ ¸å¿ƒç»„ä»¶ç‰ˆæœ¬ï¼š\n",
        "#@markdown #### PyTorchï¼š\n",
        "pytorch_ver = \"torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121\"  #@param {type:\"string\"}\n",
        "#@markdown #### xFormersï¼š\n",
        "xformers_ver = \"xformers==0.0.27\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown - ä½¿ç”¨ uv ä½œä¸º Python åŒ…ç®¡ç†å™¨\n",
        "use_uv = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown ### é€‰æ‹©å†…ç½‘ç©¿é€çš„æ–¹å¼ï¼ˆå¯¹åº”ä¸‹æ–¹çš„å‹¾é€‰æ¡†ï¼‰ï¼š\n",
        "#@markdown - ä½¿ç”¨ remote.moe å†…ç½‘ç©¿é€\n",
        "#@markdown - ä½¿ç”¨ localhost.run å†…ç½‘ç©¿é€\n",
        "#@markdown - ä½¿ç”¨ CloudFlare å†…ç½‘ç©¿é€\n",
        "#@markdown - ä½¿ç”¨ Ngrok å†…ç½‘ç©¿é€ï¼ˆéœ€å¡«å†™ Ngrok Tokenï¼Œå¯åœ¨ [Ngrok](https://ngrok.com) å®˜ç½‘è·å–ï¼‰\n",
        "#@markdown - ä½¿ç”¨ Gradio å†…ç½‘ç©¿é€\n",
        "use_remote_moe = True #@param {type:\"boolean\"}\n",
        "use_localhost_run = True #@param {type:\"boolean\"}\n",
        "use_cloudflare = True #@param {type:\"boolean\"}\n",
        "use_ngrok = False #@param {type:\"boolean\"}\n",
        "use_gradio = True #@param {type:\"boolean\"}\n",
        "#@markdown ### Ngrok Tokenï¼š\n",
        "ngrok_token = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#######################################################\n",
        "\n",
        "\n",
        "fooocus = FOOOCUS(\"/content\",\"Fooocus\")\n",
        "fooocus.install(pytorch_ver, xformers_ver, use_uv)\n",
        "fooocus.clear_up(False)\n",
        "echo(\"Fooocus è¿è¡Œç¯å¢ƒé…ç½®å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZWnei0cZwWzK"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ‘‡ ä¸‹è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼‰\n",
        "\n",
        "try:    \n",
        "    i = INIT_CONFIG\n",
        "except:\n",
        "    raise Exception(\"æœªå®‰è£… Fooocus\")\n",
        "\n",
        "# æ¨¡å‹ä¸‹è½½\n",
        "echo(\"ä¸‹è½½æ¨¡å‹ä¸­\")\n",
        "#@markdown é€‰æ‹©ä¸‹è½½çš„æ¨¡å‹ï¼š\n",
        "##############################\n",
        "\n",
        "\n",
        "sd_xl_base = False  #@param {type:\"boolean\"}\n",
        "if sd_xl_base:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors\")\n",
        "\n",
        "anima_pencil_xl = False  #@param {type:\"boolean\"}\n",
        "if anima_pencil_xl:\n",
        "    fooocus.get_sd_model(\"https://civitai.com/api/download/models/323674\", \"anima_pencil_xl.safetensors\")\n",
        "\n",
        "bluePencilXL  = False  #@param {type:\"boolean\"}\n",
        "if bluePencilXL:\n",
        "    fooocus.get_sd_model(\"https://civitai.com/api/download/models/323375\", \"bluePencilXL_v050.safetensors\")\n",
        "\n",
        "AnythingXL_xl = False  #@param {type:\"boolean\"}\n",
        "if AnythingXL_xl:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/AnythingXL_xl.safetensors\")\n",
        "\n",
        "abyssorangeXLElse_v10 = False  #@param {type:\"boolean\"}\n",
        "if abyssorangeXLElse_v10:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/abyssorangeXLElse_v10.safetensors\")\n",
        "\n",
        "CounterfeitXL  = False  #@param {type:\"boolean\"}\n",
        "if CounterfeitXL:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/CounterfeitXL-V1.0.safetensors\")\n",
        "\n",
        "animeIllustDiffusion  = False  #@param {type:\"boolean\"}\n",
        "if animeIllustDiffusion:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animeIllustDiffusion_v061.safetensors\")\n",
        "\n",
        "nekorayxl = False  #@param {type:\"boolean\"}\n",
        "if nekorayxl:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/nekorayxl_v06W3.safetensors\")\n",
        "\n",
        "animagine_XL_3 = False  #@param {type:\"boolean\"}\n",
        "if animagine_XL_3:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/cagliostrolab/animagine-xl-3.0/resolve/main/animagine-xl-3.0.safetensors\")\n",
        "\n",
        "animagine_XL_3_1 = True  #@param {type:\"boolean\"}\n",
        "if animagine_XL_3_1:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\")\n",
        "\n",
        "heartOfAppleXL_v20 = False  #@param {type:\"boolean\"}\n",
        "if heartOfAppleXL_v20:\n",
        "    fooocus.get_sd_model(\"https://civitai.com/api/download/models/337306\", \"heartOfAppleXL_v30.safetensors\")\n",
        "\n",
        "heartOfAppleXL_v30 = False  #@param {type:\"boolean\"}\n",
        "if heartOfAppleXL_v30:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/heartOfAppleXL_v30.safetensors\")\n",
        "\n",
        "holodayo_xl_21 = False  #@param {type:\"boolean\"}\n",
        "if holodayo_xl_21:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/holodayo-xl-2.1.safetensors\")\n",
        "\n",
        "kivotos_xl_20 = False  #@param {type:\"boolean\"}\n",
        "if kivotos_xl_20:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kivotos-xl-2.0.safetensors\")\n",
        "\n",
        "sd_xl_anime_V52 = False  #@param {type:\"boolean\"}\n",
        "if sd_xl_anime_V52:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sd_xl_anime_V52.safetensors\")\n",
        "\n",
        "kohakuXLGamma_rev1  = False  #@param {type:\"boolean\"}\n",
        "if kohakuXLGamma_rev1:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/KBlueLeaf/Kohaku-XL-gamma/resolve/main/kohaku-xl-gamma-rev1.safetensors\")\n",
        "\n",
        "kohakuXLBeta_beta7  = False  #@param {type:\"boolean\"}\n",
        "if kohakuXLBeta_beta7:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohakuXLBeta_beta7.safetensors\")\n",
        "\n",
        "Kohaku_XL_Delta = False  #@param {type:\"boolean\"}\n",
        "if Kohaku_XL_Delta:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/KBlueLeaf/Kohaku-XL-Delta/resolve/main/kohaku-xl-delta-rev1.safetensors\")\n",
        "\n",
        "kohakuXL_Epsilon = False  #@param {type:\"boolean\"}\n",
        "if kohakuXL_Epsilon:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/KBlueLeaf/Kohaku-XL-Epsilon/resolve/main/kohaku-xl-epsilon-rev1.safetensors\")\n",
        "\n",
        "kohakuXL_Epsilon_rev2 = False  #@param {type:\"boolean\"}\n",
        "if kohakuXL_Epsilon_rev2:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/KBlueLeaf/Kohaku-XL-Epsilon-rev2/resolve/main/kohaku-xl-epsilon-rev2.safetensors\")\n",
        "\n",
        "kohakuXL_Epsilon_rev3 = False  #@param {type:\"boolean\"}\n",
        "if kohakuXL_Epsilon_rev3:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/KBlueLeaf/Kohaku-XL-Epsilon-rev3/resolve/main/kohaku-xl-epsilon-rev3.safetensors\")\n",
        "\n",
        "kohakuXL_Zeta = True  #@param {type:\"boolean\"}\n",
        "if kohakuXL_Zeta:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/KBlueLeaf/Kohaku-XL-Zeta/resolve/main/kohaku-xl-zeta.safetensors\")\n",
        "\n",
        "starryXLV52 = False  #@param {type:\"boolean\"}\n",
        "if starryXLV52:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/starryXLV52_v52.safetensors\")\n",
        "\n",
        "BArtstyleDB = False  #@param {type:\"boolean\"}\n",
        "if BArtstyleDB:\n",
        "    fooocus.get_sd_model(\"https://civitai.com/api/download/models/299095\", \"BArtstyleDB_XL.safetensors\")\n",
        "\n",
        "BArtstyleDB_3 = False  #@param {type:\"boolean\"}\n",
        "if BArtstyleDB_3:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/baxlBlueArchiveFlatCelluloidStyle_xlv3.safetensors\")\n",
        "\n",
        "pony_v6 = False  #@param {type:\"boolean\"}\n",
        "if pony_v6:\n",
        "    fooocus.get_sd_model(\"https://civitai.com/api/download/models/290640\", \"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\")\n",
        "\n",
        "pdForAnime_v20 = False  #@param {type:\"boolean\"}\n",
        "if pdForAnime_v20:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/pdForAnime_v20.safetensors\")\n",
        "\n",
        "tPonynai3_v51 = False  #@param {type:\"boolean\"}\n",
        "if tPonynai3_v51:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/tPonynai3_v51WeightOptimized.safetensors\")\n",
        "\n",
        "omegaPonyXLAnime_v20 = False  #@param {type:\"boolean\"}\n",
        "if omegaPonyXLAnime_v20:\n",
        "    fooocus.get_sd_model(\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/omegaPonyXLAnime_v20.safetensors\")\n",
        "\n",
        "\n",
        "##############################\n",
        "fooocus.clear_up(False)\n",
        "echo(\"æ¨¡å‹ä¸‹è½½å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cLB6sKhErcG8"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ‘‡ å¯åŠ¨ Fooocusï¼ˆå›¾ç‰‡ä¿å­˜åœ¨ Google Driveï¼‰\n",
        "try:    \n",
        "    i = INIT_CONFIG\n",
        "except:\n",
        "    raise Exception(\"æœªå®‰è£… Fooocus\")\n",
        "\n",
        "echo(\"å¯åŠ¨ Fooocus\")\n",
        "import os\n",
        "os.chdir(\"/content/Fooocus\")\n",
        "fooocus.config_google_drive()\n",
        "fooocus.tun.start(ngrok=use_ngrok, ngrok_token=ngrok_token, cloudflare=use_cloudflare, remote_moe=use_remote_moe, localhost_run=use_localhost_run, gradio=False)\n",
        "if use_gradio:\n",
        "    !python /content/Fooocus/launch.py --preset custom --language zh --disable-offload-from-vram --async-cuda-allocation --share --disable-analytics\n",
        "else:\n",
        "    !python /content/Fooocus/launch.py --preset custom --language zh --disable-offload-from-vram --async-cuda-allocation --disable-analytics\n",
        "fooocus.clear_up(False)\n",
        "echo(\"å·²å…³é—­ Fooocus\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eTRqHk4yMMg"
      },
      "source": [
        "### âœ¨ å…¶ä»–åŠŸèƒ½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YuIlDy-KQ5tX"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ‘‡ è‡ªå®šä¹‰æ¨¡å‹ä¸‹è½½\n",
        "try:    \n",
        "    i = INIT_CONFIG\n",
        "except:\n",
        "    raise Exception(\"æœªå®‰è£… Fooocus\")\n",
        "\n",
        "#@markdown ### é€‰æ‹©æ¨¡å‹ç§ç±»ï¼š\n",
        "#@markdown - Stable Diffusionï¼ˆå¤§æ¨¡å‹ï¼‰æ¨¡å‹\n",
        "#@markdown - LoRAæ¨¡å‹\n",
        "model_type = \"LoRA\" # @param [\"Stable Diffusion\", \"LoRA\"]\n",
        "#@markdown ###å¡«å†™æ¨¡å‹çš„ä¸‹è½½é“¾æ¥ï¼š\n",
        "model_url = \"https://huggingface.co/licyk/sd-lora/resolve/main/sdxl/style/CoolFlatColor.safetensors\"  #@param {type:\"string\"}\n",
        "#@markdown ###å¡«å†™æ¨¡å‹çš„åç§°ï¼ˆåŒ…æ‹¬åç¼€åï¼‰ï¼š\n",
        "model_name = \"CoolFlatColor.safetensors\"  #@param {type:\"string\"}\n",
        "\n",
        "if model_type == \"Stable Diffusion\":\n",
        "    fooocus.get_sd_model(model_url, model_name)\n",
        "elif model_type == \"LoRA\":\n",
        "    fooocus.get_lora_model(model_url, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DGsBdT4G5-Ky"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ‘‡ å¯åŠ¨Fooocusï¼ˆå›¾ç‰‡ä¿å­˜åœ¨ Colabï¼‰\n",
        "try:    \n",
        "    i = INIT_CONFIG\n",
        "except:\n",
        "    raise Exception(\"æœªå®‰è£… Fooocus\")\n",
        "echo(\"å¯åŠ¨ Fooocus\")\n",
        "import os\n",
        "os.chdir(\"/content/Fooocus\")\n",
        "fooocus.tun.start(ngrok=use_ngrok, ngrok_token=ngrok_token, cloudflare=use_cloudflare, remote_moe=use_remote_moe, localhost_run=use_localhost_run, gradio=False)\n",
        "if use_gradio:\n",
        "    !python /content/Fooocus/launch.py --preset custom --language zh --disable-offload-from-vram --async-cuda-allocation --share\n",
        "else:\n",
        "    !python /content/Fooocus/launch.py --preset custom --language zh --disable-offload-from-vram --async-cuda-allocation\n",
        "fooocus.clear_up(False)\n",
        "echo(\"å·²å…³é—­ Fooocus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T84S1hZt0wp_"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ‘‡æŒ‚è½½ Google Drive å¹¶å¤‡ä»½å›¾ç‰‡\n",
        "try:    \n",
        "    i = INIT_CONFIG\n",
        "except:\n",
        "    raise Exception(\"æœªå®‰è£… Fooocus\")\n",
        "fooocus.config_google_drive()\n",
        "echo(\"å¤‡ä»½å›¾ç‰‡ä¸­\")\n",
        "!cp -r /content/drive/MyDrive/fooocus_output/* /content/drive_/MyDrive/fooocus_output\n",
        "echo(\"å¤‡ä»½å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WaamR1AcmTFv"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ‘‡è¿œç¨‹å…±äº«æ–¹å¼ä¿®æ”¹\n",
        "#@markdown ### é€‰æ‹©å†…ç½‘ç©¿é€çš„æ–¹å¼ï¼ˆå¯¹åº”ä¸‹æ–¹çš„å‹¾é€‰æ¡†ï¼‰ï¼š\n",
        "#@markdown - ä½¿ç”¨ remote.moe å†…ç½‘ç©¿é€\n",
        "#@markdown - ä½¿ç”¨ localhost.run å†…ç½‘ç©¿é€\n",
        "#@markdown - ä½¿ç”¨ CloudFlare å†…ç½‘ç©¿é€\n",
        "#@markdown - ä½¿ç”¨ Ngrok å†…ç½‘ç©¿é€ï¼ˆéœ€å¡«å†™ Ngrok Tokenï¼Œå¯åœ¨ [Ngrok](https://ngrok.com) å®˜ç½‘è·å–ï¼‰\n",
        "#@markdown - ä½¿ç”¨ Gradio å†…ç½‘ç©¿é€\n",
        "use_remote_moe = True #@param {type:\"boolean\"}\n",
        "use_localhost_run = True #@param {type:\"boolean\"}\n",
        "use_cloudflare = True #@param {type:\"boolean\"}\n",
        "use_ngrok = False #@param {type:\"boolean\"}\n",
        "use_gradio = True #@param {type:\"boolean\"}\n",
        "#@markdown ### Ngrok Tokenï¼š\n",
        "ngrok_token = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "echo(\"è®¾ç½®å…±äº«æ–¹å¼å®Œæˆ\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6eTRqHk4yMMg"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
